Python version:  3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]
Command line arguments:
mode: train
dataset: CIFAR10
model: ResNet101
epochs: 100
lr: 0.1
momentum: 0.9
weight_decay: 0.0005
image: ./test
showplot: False


Files already downloaded and verified
Files already downloaded and verified
====Device: cuda:0
Mode: Training, Dataset: CIFAR10, Model: ResNet101, Model file: ResNet101_CIFAR10_best.pth
Epoch 1/100
Train Loss: 6.5019 Acc: 0.0986
Test Loss: 2.6868 Acc: 0.1057

Epoch 2/100
Train Loss: 2.7351 Acc: 0.1297
Test Loss: 12.0221 Acc: 0.1164

Epoch 3/100
Train Loss: 2.5812 Acc: 0.1444
Test Loss: 2.4156 Acc: 0.1356

Epoch 4/100
Train Loss: 2.3528 Acc: 0.1806
Test Loss: 2.1484 Acc: 0.1492

Epoch 5/100
Train Loss: 2.0903 Acc: 0.2146
Test Loss: 2.1955 Acc: 0.2104

Epoch 6/100
Train Loss: 2.0178 Acc: 0.2411
Test Loss: 2.0162 Acc: 0.2439

Epoch 7/100
Train Loss: 1.9488 Acc: 0.2613
Test Loss: 1.8393 Acc: 0.2943

Epoch 8/100
Train Loss: 1.8716 Acc: 0.2957
Test Loss: 1.8336 Acc: 0.2868

Epoch 9/100
Train Loss: 1.8239 Acc: 0.3118
Test Loss: 2.0493 Acc: 0.3066

Epoch 10/100
Train Loss: 1.7928 Acc: 0.3353
Test Loss: 1.6822 Acc: 0.3716

Epoch 11/100
Train Loss: 1.7315 Acc: 0.3543
Test Loss: 1.6365 Acc: 0.3912

Epoch 12/100
Train Loss: 1.6693 Acc: 0.3795
Test Loss: 1.6316 Acc: 0.3960

Epoch 13/100
Train Loss: 1.6061 Acc: 0.4063
Test Loss: 1.5528 Acc: 0.4278

Epoch 14/100
Train Loss: 1.5665 Acc: 0.4244
Test Loss: 1.5232 Acc: 0.4436

Epoch 15/100
Train Loss: 1.5209 Acc: 0.4417
Test Loss: 1.4393 Acc: 0.4740

Epoch 16/100
Train Loss: 1.4743 Acc: 0.4600
Test Loss: 1.4432 Acc: 0.4773

Epoch 17/100
Train Loss: 1.4325 Acc: 0.4797
Test Loss: 1.4621 Acc: 0.4698

Epoch 18/100
Train Loss: 1.3988 Acc: 0.4896
Test Loss: 1.3507 Acc: 0.5071

Epoch 19/100
Train Loss: 1.3465 Acc: 0.5132
Test Loss: 1.2853 Acc: 0.5367

Epoch 20/100
Train Loss: 1.3159 Acc: 0.5277
Test Loss: 1.2740 Acc: 0.5401

Epoch 21/100
Train Loss: 1.2746 Acc: 0.5426
Test Loss: 1.2298 Acc: 0.5646

Epoch 22/100
Train Loss: 1.2407 Acc: 0.5523
Test Loss: 1.2203 Acc: 0.5596

Epoch 23/100
Train Loss: 1.1990 Acc: 0.5728
Test Loss: 1.1516 Acc: 0.5938

Epoch 24/100
Train Loss: 1.1596 Acc: 0.5886
Test Loss: 1.1484 Acc: 0.5928

Epoch 25/100
Train Loss: 1.1318 Acc: 0.5973
Test Loss: 1.0802 Acc: 0.6186

Epoch 26/100
Train Loss: 1.0907 Acc: 0.6131
Test Loss: 1.1035 Acc: 0.6137

Epoch 27/100
Train Loss: 1.0514 Acc: 0.6269
Test Loss: 1.0142 Acc: 0.6464

Epoch 28/100
Train Loss: 1.0263 Acc: 0.6370
Test Loss: 1.0469 Acc: 0.6273

Epoch 29/100
Train Loss: 0.9933 Acc: 0.6485
Test Loss: 1.0031 Acc: 0.6494

Epoch 30/100
Train Loss: 0.9677 Acc: 0.6592
Test Loss: 0.9847 Acc: 0.6565

Epoch 31/100
Train Loss: 0.9382 Acc: 0.6693
Test Loss: 0.9596 Acc: 0.6717

Epoch 32/100
Train Loss: 0.9084 Acc: 0.6793
Test Loss: 0.9492 Acc: 0.6700

Epoch 33/100
Train Loss: 0.8832 Acc: 0.6900
Test Loss: 0.8957 Acc: 0.6878

Epoch 34/100
Train Loss: 0.8592 Acc: 0.7003
Test Loss: 0.8754 Acc: 0.6965

Epoch 35/100
Train Loss: 0.8352 Acc: 0.7099
Test Loss: 0.8972 Acc: 0.6919

Epoch 36/100
Train Loss: 0.8167 Acc: 0.7153
Test Loss: 0.9275 Acc: 0.6787

Epoch 37/100
Train Loss: 0.8004 Acc: 0.7203
Test Loss: 0.8891 Acc: 0.6972

Epoch 38/100
Train Loss: 0.7784 Acc: 0.7287
Test Loss: 0.8391 Acc: 0.7134

Epoch 39/100
Train Loss: 0.7531 Acc: 0.7380
Test Loss: 0.9067 Acc: 0.6966

Epoch 40/100
Train Loss: 0.7550 Acc: 0.7367
Test Loss: 0.8358 Acc: 0.7131

Epoch 41/100
Train Loss: 0.7384 Acc: 0.7425
Test Loss: 0.8478 Acc: 0.7071

Epoch 42/100
Train Loss: 0.7168 Acc: 0.7496
Test Loss: 0.7423 Acc: 0.7490

Epoch 43/100
Train Loss: 0.7016 Acc: 0.7563
Test Loss: 0.7761 Acc: 0.7345

Epoch 44/100
Train Loss: 0.7023 Acc: 0.7540
Test Loss: 0.7727 Acc: 0.7321

Epoch 45/100
Train Loss: 0.7034 Acc: 0.7527
Test Loss: 0.8161 Acc: 0.7185

Epoch 46/100
Train Loss: 0.7047 Acc: 0.7535
Test Loss: 0.7916 Acc: 0.7279

Epoch 47/100
Train Loss: 0.6658 Acc: 0.7669
Test Loss: 0.8229 Acc: 0.7230

Epoch 48/100
Train Loss: 0.6531 Acc: 0.7721
Test Loss: 0.7222 Acc: 0.7531

Epoch 49/100
Train Loss: 0.6404 Acc: 0.7766
Test Loss: 0.7328 Acc: 0.7480

Epoch 50/100
Train Loss: 0.6327 Acc: 0.7793
Test Loss: 0.7174 Acc: 0.7566

Epoch 51/100
Train Loss: 0.5103 Acc: 0.8242
Test Loss: 0.5614 Acc: 0.8061

Epoch 52/100
Train Loss: 0.4646 Acc: 0.8389
Test Loss: 0.5480 Acc: 0.8137

Epoch 53/100
Train Loss: 0.4429 Acc: 0.8456
Test Loss: 0.5433 Acc: 0.8156

Epoch 54/100
Train Loss: 0.4276 Acc: 0.8517
Test Loss: 0.5416 Acc: 0.8169

Epoch 55/100
Train Loss: 0.4081 Acc: 0.8572
Test Loss: 0.5394 Acc: 0.8164

Epoch 56/100
Train Loss: 0.4047 Acc: 0.8591
Test Loss: 0.5439 Acc: 0.8171

Epoch 57/100
Train Loss: 0.3948 Acc: 0.8612
Test Loss: 0.5484 Acc: 0.8153

Epoch 58/100
Train Loss: 0.3869 Acc: 0.8654
Test Loss: 0.5505 Acc: 0.8180

Epoch 59/100
Train Loss: 0.3792 Acc: 0.8677
Test Loss: 0.5406 Acc: 0.8197

Epoch 60/100
Train Loss: 0.3677 Acc: 0.8714
Test Loss: 0.5511 Acc: 0.8168

Epoch 61/100
Train Loss: 0.3620 Acc: 0.8731
Test Loss: 0.5526 Acc: 0.8214

Epoch 62/100
Train Loss: 0.3539 Acc: 0.8763
Test Loss: 0.5471 Acc: 0.8247

Epoch 63/100
Train Loss: 0.3503 Acc: 0.8784
Test Loss: 0.5492 Acc: 0.8238

Epoch 64/100
Train Loss: 0.3417 Acc: 0.8795
Test Loss: 0.5626 Acc: 0.8162

Epoch 65/100
Train Loss: 0.3312 Acc: 0.8832
Test Loss: 0.5675 Acc: 0.8176

Epoch 66/100
Train Loss: 0.3285 Acc: 0.8859
Test Loss: 0.5638 Acc: 0.8192

Epoch 67/100
Train Loss: 0.3269 Acc: 0.8856
Test Loss: 0.5602 Acc: 0.8244

Epoch 68/100
Train Loss: 0.3148 Acc: 0.8905
Test Loss: 0.5656 Acc: 0.8214

Epoch 69/100
Train Loss: 0.3068 Acc: 0.8938
Test Loss: 0.5663 Acc: 0.8231

Epoch 70/100
Train Loss: 0.3103 Acc: 0.8911
Test Loss: 0.5844 Acc: 0.8186

Epoch 71/100
Train Loss: 0.2983 Acc: 0.8958
Test Loss: 0.5823 Acc: 0.8182

Epoch 72/100
Train Loss: 0.2953 Acc: 0.8955
Test Loss: 0.5778 Acc: 0.8210

Epoch 73/100
Train Loss: 0.2856 Acc: 0.9006
Test Loss: 0.5924 Acc: 0.8211

Epoch 74/100
Train Loss: 0.2781 Acc: 0.9026
Test Loss: 0.5936 Acc: 0.8245

Epoch 75/100
Train Loss: 0.2785 Acc: 0.9033
Test Loss: 0.5875 Acc: 0.8181

Epoch 76/100
Train Loss: 0.2474 Acc: 0.9145
Test Loss: 0.5653 Acc: 0.8289

Epoch 77/100
Train Loss: 0.2407 Acc: 0.9164
Test Loss: 0.5690 Acc: 0.8267

Epoch 78/100
Train Loss: 0.2361 Acc: 0.9180
Test Loss: 0.5703 Acc: 0.8269

Epoch 79/100
Train Loss: 0.2293 Acc: 0.9215
Test Loss: 0.5734 Acc: 0.8265

Epoch 80/100
Train Loss: 0.2258 Acc: 0.9241
Test Loss: 0.5747 Acc: 0.8292

Epoch 81/100
Train Loss: 0.2227 Acc: 0.9237
Test Loss: 0.5785 Acc: 0.8280

Epoch 82/100
Train Loss: 0.2185 Acc: 0.9241
Test Loss: 0.5796 Acc: 0.8298

Epoch 83/100
Train Loss: 0.2165 Acc: 0.9257
Test Loss: 0.5824 Acc: 0.8280

Epoch 84/100
Train Loss: 0.2121 Acc: 0.9263
Test Loss: 0.5841 Acc: 0.8298

Epoch 85/100
Train Loss: 0.2088 Acc: 0.9266
Test Loss: 0.5869 Acc: 0.8293

Epoch 86/100
Train Loss: 0.2091 Acc: 0.9263
Test Loss: 0.5897 Acc: 0.8281

Epoch 87/100
Train Loss: 0.2099 Acc: 0.9277
Test Loss: 0.5918 Acc: 0.8282

Epoch 88/100
Train Loss: 0.2070 Acc: 0.9285
Test Loss: 0.5960 Acc: 0.8263

Epoch 89/100
Train Loss: 0.2047 Acc: 0.9294
Test Loss: 0.5952 Acc: 0.8281

Epoch 90/100
Train Loss: 0.2068 Acc: 0.9290
Test Loss: 0.6002 Acc: 0.8274

Epoch 91/100
Train Loss: 0.1988 Acc: 0.9316
Test Loss: 0.6015 Acc: 0.8257

Epoch 92/100
Train Loss: 0.1990 Acc: 0.9309
Test Loss: 0.6024 Acc: 0.8275

Epoch 93/100
Train Loss: 0.1978 Acc: 0.9318
Test Loss: 0.6022 Acc: 0.8302

Epoch 94/100
Train Loss: 0.1946 Acc: 0.9336
Test Loss: 0.6041 Acc: 0.8263

Epoch 95/100
Train Loss: 0.1963 Acc: 0.9315
Test Loss: 0.6046 Acc: 0.8277

Epoch 96/100
Train Loss: 0.1887 Acc: 0.9359
Test Loss: 0.6073 Acc: 0.8276

Epoch 97/100
Train Loss: 0.1928 Acc: 0.9342
Test Loss: 0.6077 Acc: 0.8271

Epoch 98/100
Train Loss: 0.1891 Acc: 0.9348
Test Loss: 0.6052 Acc: 0.8297

Epoch 99/100
Train Loss: 0.1901 Acc: 0.9341
Test Loss: 0.6118 Acc: 0.8281

Epoch 100/100
Train Loss: 0.1840 Acc: 0.9361
Test Loss: 0.6106 Acc: 0.8280

Training complete in 171m 4s
Best val Acc: 0.830200
+-------+---------------------+---------------------+--------------------+---------------------+
| Epoch |      Train Loss     |      Train Acc      |     Test Loss      |       Test ACC      |
+-------+---------------------+---------------------+--------------------+---------------------+
|   1   |  6.501916618423462  | 0.09862000000000001 | 2.6867728702545164 |        0.1057       |
|   2   |  2.735138362350464  |        0.1297       | 12.022130783081055 |        0.1164       |
|   3   |  2.5812277547454836 |       0.14444       | 2.415567038345337  |        0.1356       |
|   4   |  2.3527578452301023 | 0.18058000000000002 | 2.1484458797454833 |        0.1492       |
|   5   |  2.0902858044052124 | 0.21458000000000002 | 2.1954701528549196 |        0.2104       |
|   6   |   2.01781251121521  |        0.2411       | 2.016242658233643  |        0.2439       |
|   7   |  1.9488042818832398 | 0.26130000000000003 | 1.839290551185608  |        0.2943       |
|   8   |  1.8716392026519775 |        0.2957       | 1.8335533081054687 |        0.2868       |
|   9   |  1.8239081884384156 | 0.31176000000000004 | 2.049283363342285  | 0.30660000000000004 |
|   10  |  1.7928206936264037 |       0.33528       | 1.6821707109451294 | 0.37160000000000004 |
|   11  |  1.7315218824005127 |       0.35426       | 1.6365466464996339 |        0.3912       |
|   12  |  1.6693489622116089 | 0.37954000000000004 | 1.6315577529907226 |        0.396        |
|   13  |  1.6060804383850098 | 0.40628000000000003 | 1.552844309425354  |        0.4278       |
|   14  |  1.5665372785949707 | 0.42444000000000004 | 1.523230302619934  |        0.4436       |
|   15  |  1.5209155997848511 | 0.44166000000000005 | 1.439271411895752  | 0.47400000000000003 |
|   16  |  1.474291830368042  | 0.46004000000000006 | 1.4432366748809815 |        0.4773       |
|   17  |  1.4324745961761474 | 0.47972000000000004 | 1.462131950187683  |        0.4698       |
|   18  |  1.3988250566101075 | 0.48956000000000005 | 1.350681442451477  |        0.5071       |
|   19  |  1.3465181099700927 |  0.5131800000000001 | 1.2853449245452881 |  0.5367000000000001 |
|   20  |  1.3159094876861572 |       0.52768       | 1.2739775833129883 |        0.5401       |
|   21  |  1.2746483513259887 |  0.5426000000000001 | 1.229844087791443  |        0.5646       |
|   22  |  1.2407098369216918 |        0.5523       | 1.2202623287200929 |        0.5596       |
|   23  |  1.1990252612686156 |       0.57276       | 1.1515928020477295 |        0.5938       |
|   24  |  1.1595989168548584 |        0.5886       | 1.1484073732376099 |        0.5928       |
|   25  |  1.1318030200576783 |  0.5973200000000001 | 1.0802357009887695 |        0.6186       |
|   26  |  1.0907241382980346 |       0.61306       | 1.1035063667297362 |        0.6137       |
|   27  |  1.0513976943969727 |       0.62694       | 1.0141550104141235 |  0.6464000000000001 |
|   28  |  1.0262800881958007 |       0.63702       | 1.0469496410369874 |  0.6273000000000001 |
|   29  |  0.993313969783783  |       0.64854       | 1.0030770456314086 |        0.6494       |
|   30  |  0.9677251454162598 |  0.6591800000000001 | 0.9847009593963623 |  0.6565000000000001 |
|   31  |  0.9381910263824463 |  0.6692600000000001 | 0.9595802659988404 |  0.6717000000000001 |
|   32  |  0.9083833869552612 |  0.6792600000000001 | 0.9491919361114501 |         0.67        |
|   33  |  0.883206372089386  |  0.6900000000000001 | 0.8957029052734375 |  0.6878000000000001 |
|   34  |  0.8591750269317627 |        0.7003       | 0.8754088312149048 |        0.6965       |
|   35  |  0.8351649067497253 |  0.7099000000000001 | 0.8971724078178406 |  0.6919000000000001 |
|   36  |  0.8166615857124329 |        0.7153       | 0.9275231086730957 |  0.6787000000000001 |
|   37  |  0.8004466759681702 |       0.72026       | 0.8891410217285156 |        0.6972       |
|   38  |  0.7784202173042297 |       0.72874       | 0.8391004250526428 |        0.7134       |
|   39  |  0.753104230556488  |       0.73802       | 0.9067432874679565 |        0.6966       |
|   40  |  0.7550314233970642 |       0.73672       | 0.8357736904144287 |  0.7131000000000001 |
|   41  |  0.7384239838600158 |  0.7425200000000001 | 0.8477721348762512 |  0.7071000000000001 |
|   42  |  0.7168244876670837 |  0.7496400000000001 | 0.742261519241333  |        0.749        |
|   43  |  0.7015583380508423 |  0.7562800000000001 | 0.7761321906089783 |        0.7345       |
|   44  |  0.702302346534729  |       0.75402       | 0.7726501176834106 |  0.7321000000000001 |
|   45  |  0.7033928566551209 |       0.75268       | 0.816065972328186  |        0.7185       |
|   46  |  0.7046601435470581 |  0.7535000000000001 | 0.7916360019683838 |        0.7279       |
|   47  |  0.6658194721794128 |  0.7669400000000001 | 0.8228605765342712 |  0.7230000000000001 |
|   48  |  0.653104262599945  |  0.7720800000000001 | 0.7222458388328552 |        0.7531       |
|   49  |  0.6403899222946167 |  0.7766200000000001 | 0.7327892287254334 |        0.748        |
|   50  |  0.6327416328811646 |  0.7793000000000001 | 0.7174081869125366 |        0.7566       |
|   51  |  0.5103388555240631 |  0.8242200000000001 | 0.5613701120376587 |        0.8061       |
|   52  |  0.464642721529007  |  0.8389000000000001 | 0.5480138680458069 |  0.8137000000000001 |
|   53  |  0.4429281487178803 |  0.8455600000000001 | 0.5433344576835633 |        0.8156       |
|   54  | 0.42759078642845155 |  0.8516800000000001 | 0.5416127627372742 |  0.8169000000000001 |
|   55  |  0.408142821187973  |  0.8572000000000001 | 0.5394195342063903 |        0.8164       |
|   56  | 0.40473166293144225 |  0.8590800000000001 | 0.5438620812416076 |        0.8171       |
|   57  | 0.39476684357643127 |  0.8611800000000001 | 0.5484392530441284 |        0.8153       |
|   58  |  0.3869385117149353 |  0.8654400000000001 | 0.5504943842887878 |  0.8180000000000001 |
|   59  |  0.3791993744087219 |  0.8677400000000001 | 0.5405790031433105 |        0.8197       |
|   60  | 0.36772687076568605 |       0.87138       | 0.5511241126060485 |  0.8168000000000001 |
|   61  |  0.3619541898345947 |  0.8731200000000001 | 0.5525575566291809 |        0.8214       |
|   62  |  0.353857006444931  |  0.8763400000000001 | 0.5470572813987732 |        0.8247       |
|   63  | 0.35034394963264465 |  0.8784200000000001 | 0.5491875217437744 |  0.8238000000000001 |
|   64  | 0.34172416341781614 |  0.8795000000000001 | 0.5625933103561401 |        0.8162       |
|   65  | 0.33124163687705993 |  0.8832200000000001 | 0.5675302884101868 |        0.8176       |
|   66  | 0.32854821932792666 |  0.8859400000000001 | 0.5637554794311523 |        0.8192       |
|   67  | 0.32693970017433166 |  0.8856400000000001 | 0.5601880858421325 |        0.8244       |
|   68  | 0.31476609555244445 |  0.8905200000000001 |  0.56555547914505  |        0.8214       |
|   69  |  0.3068251537513733 |  0.8937600000000001 | 0.5663135130882263 |        0.8231       |
|   70  | 0.31028427250862123 |  0.8910800000000001 | 0.5844277863502503 |        0.8186       |
|   71  | 0.29831184745788575 |       0.89578       | 0.5822603819847106 |        0.8182       |
|   72  |  0.2952975855255127 |  0.8955400000000001 | 0.5778395069122314 |  0.8210000000000001 |
|   73  |  0.285614955739975  |  0.9006200000000001 | 0.5924311279296876 |        0.8211       |
|   74  | 0.27809509757995604 |  0.9026200000000001 | 0.5936361794471741 |        0.8245       |
|   75  | 0.27849156646251677 |  0.9032600000000001 | 0.5874853866577149 |        0.8181       |
|   76  | 0.24742834773540498 |  0.9144800000000001 | 0.5652949970245361 |  0.8289000000000001 |
|   77  | 0.24072732008457184 |  0.9163800000000001 | 0.5689761775970459 |        0.8267       |
|   78  | 0.23605733553886413 |  0.9179600000000001 | 0.5703238195419311 |  0.8269000000000001 |
|   79  | 0.22933839018821717 |  0.9215000000000001 | 0.573367179775238  |        0.8265       |
|   80  | 0.22582566378593444 |       0.92412       | 0.574722562122345  |        0.8292       |
|   81  | 0.22273987855911254 |       0.92366       | 0.5785088013648987 |  0.8280000000000001 |
|   82  | 0.21850702579021453 |  0.9240600000000001 | 0.5795589545249938 |  0.8298000000000001 |
|   83  | 0.21652000737190247 |       0.92566       | 0.5823848365783691 |  0.8280000000000001 |
|   84  |  0.2120537477350235 |  0.9262600000000001 | 0.5840735155105591 |  0.8298000000000001 |
|   85  | 0.20877366258621216 |  0.9265800000000001 | 0.5868591201782226 |        0.8293       |
|   86  | 0.20905260886669158 |  0.9262600000000001 | 0.5897379424095154 |  0.8281000000000001 |
|   87  | 0.20989677899360656 |  0.9276800000000001 | 0.5917550813674927 |        0.8282       |
|   88  | 0.20703637098789215 |  0.9284600000000001 | 0.5960360737800598 |        0.8263       |
|   89  |  0.2046915326309204 |  0.9294000000000001 | 0.5952151725769043 |  0.8281000000000001 |
|   90  | 0.20675074985980987 |  0.9290200000000001 | 0.6002359709739685 |        0.8274       |
|   91  | 0.19879574677944184 |  0.9315800000000001 | 0.6015365878105163 |        0.8257       |
|   92  | 0.19904997181892395 |  0.9309400000000001 | 0.6023852916717529 |        0.8275       |
|   93  |  0.1977928827238083 |       0.93176       | 0.6022474038124085 |        0.8302       |
|   94  | 0.19456282802581787 |  0.9335800000000001 | 0.6040634440422058 |        0.8263       |
|   95  | 0.19628726410388947 |  0.9315200000000001 | 0.6046085793495178 |        0.8277       |
|   96  |  0.1886844127035141 |       0.93586       | 0.6073102961540222 |        0.8276       |
|   97  |  0.1928209351825714 |        0.9342       | 0.6076825383186341 |  0.8271000000000001 |
|   98  | 0.18911602153778076 |  0.9348200000000001 | 0.6052418822288513 |        0.8297       |
|   99  |  0.1900818439102173 |  0.9341400000000001 | 0.6117539602279664 |  0.8281000000000001 |
|  100  | 0.18395340210914612 |       0.93608       | 0.6105628358840942 |  0.8280000000000001 |
+-------+---------------------+---------------------+--------------------+---------------------+
Time elapsed: 10267.35 seconds
