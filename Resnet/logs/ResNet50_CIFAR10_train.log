Python version:  3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]
Command line arguments:
mode: train
dataset: CIFAR10
model: ResNet50
epochs: 100
lr: 0.1
momentum: 0.9
weight_decay: 0.0005
image: ./test
showplot: False


Files already downloaded and verified
Files already downloaded and verified
====Device: cuda:0
Mode: Training, Dataset: CIFAR10, Model: ResNet50, Model file: ResNet50_CIFAR10_best.pth
Epoch 1/100
Train Loss: 5.5977 Acc: 0.1012
Test Loss: 2.3178 Acc: 0.1014

Epoch 2/100
Train Loss: 2.8182 Acc: 0.1020
Test Loss: 152.6650 Acc: 0.0978

Epoch 3/100
Train Loss: 2.6622 Acc: 0.1007
Test Loss: 2.3053 Acc: 0.1005

Epoch 4/100
Train Loss: 2.5160 Acc: 0.1063
Test Loss: 2.3013 Acc: 0.1044

Epoch 5/100
Train Loss: 2.4249 Acc: 0.1220
Test Loss: 2.2546 Acc: 0.1559

Epoch 6/100
Train Loss: 2.2606 Acc: 0.1829
Test Loss: 2.0485 Acc: 0.2030

Epoch 7/100
Train Loss: 2.0272 Acc: 0.2252
Test Loss: 1.8942 Acc: 0.2569

Epoch 8/100
Train Loss: 1.9511 Acc: 0.2633
Test Loss: 1.8714 Acc: 0.3044

Epoch 9/100
Train Loss: 1.8987 Acc: 0.2873
Test Loss: 1.7848 Acc: 0.3227

Epoch 10/100
Train Loss: 1.7865 Acc: 0.3303
Test Loss: 1.6458 Acc: 0.3944

Epoch 11/100
Train Loss: 1.6655 Acc: 0.3802
Test Loss: 1.5322 Acc: 0.4316

Epoch 12/100
Train Loss: 1.5705 Acc: 0.4199
Test Loss: 1.4785 Acc: 0.4568

Epoch 13/100
Train Loss: 1.5049 Acc: 0.4478
Test Loss: 1.3959 Acc: 0.4883

Epoch 14/100
Train Loss: 1.4318 Acc: 0.4772
Test Loss: 1.4106 Acc: 0.4828

Epoch 15/100
Train Loss: 1.3773 Acc: 0.4975
Test Loss: 1.3011 Acc: 0.5191

Epoch 16/100
Train Loss: 1.3246 Acc: 0.5185
Test Loss: 1.2385 Acc: 0.5521

Epoch 17/100
Train Loss: 1.2612 Acc: 0.5428
Test Loss: 1.2846 Acc: 0.5310

Epoch 18/100
Train Loss: 1.2052 Acc: 0.5651
Test Loss: 1.1899 Acc: 0.5709

Epoch 19/100
Train Loss: 1.1523 Acc: 0.5851
Test Loss: 1.1205 Acc: 0.6021

Epoch 20/100
Train Loss: 1.0863 Acc: 0.6108
Test Loss: 1.0364 Acc: 0.6330

Epoch 21/100
Train Loss: 1.0391 Acc: 0.6276
Test Loss: 1.0650 Acc: 0.6261

Epoch 22/100
Train Loss: 0.9862 Acc: 0.6470
Test Loss: 1.0550 Acc: 0.6341

Epoch 23/100
Train Loss: 0.9398 Acc: 0.6644
Test Loss: 0.9948 Acc: 0.6578

Epoch 24/100
Train Loss: 0.9081 Acc: 0.6779
Test Loss: 0.9678 Acc: 0.6654

Epoch 25/100
Train Loss: 0.8741 Acc: 0.6936
Test Loss: 0.8752 Acc: 0.6984

Epoch 26/100
Train Loss: 0.8381 Acc: 0.7040
Test Loss: 0.8890 Acc: 0.6926

Epoch 27/100
Train Loss: 0.8067 Acc: 0.7162
Test Loss: 0.8343 Acc: 0.7077

Epoch 28/100
Train Loss: 0.7813 Acc: 0.7244
Test Loss: 0.7889 Acc: 0.7245

Epoch 29/100
Train Loss: 0.7610 Acc: 0.7322
Test Loss: 0.8085 Acc: 0.7233

Epoch 30/100
Train Loss: 0.7395 Acc: 0.7407
Test Loss: 0.7967 Acc: 0.7245

Epoch 31/100
Train Loss: 0.7220 Acc: 0.7476
Test Loss: 0.7878 Acc: 0.7270

Epoch 32/100
Train Loss: 0.7041 Acc: 0.7559
Test Loss: 0.7903 Acc: 0.7252

Epoch 33/100
Train Loss: 0.6868 Acc: 0.7606
Test Loss: 0.7564 Acc: 0.7349

Epoch 34/100
Train Loss: 0.6834 Acc: 0.7624
Test Loss: 0.7212 Acc: 0.7492

Epoch 35/100
Train Loss: 0.6587 Acc: 0.7694
Test Loss: 0.7027 Acc: 0.7575

Epoch 36/100
Train Loss: 0.6556 Acc: 0.7693
Test Loss: 0.7790 Acc: 0.7290

Epoch 37/100
Train Loss: 0.6327 Acc: 0.7802
Test Loss: 0.7238 Acc: 0.7536

Epoch 38/100
Train Loss: 0.6189 Acc: 0.7849
Test Loss: 0.7174 Acc: 0.7551

Epoch 39/100
Train Loss: 0.6177 Acc: 0.7855
Test Loss: 0.6874 Acc: 0.7613

Epoch 40/100
Train Loss: 0.6029 Acc: 0.7922
Test Loss: 0.6435 Acc: 0.7847

Epoch 41/100
Train Loss: 0.6143 Acc: 0.7863
Test Loss: 0.7636 Acc: 0.7420

Epoch 42/100
Train Loss: 0.5886 Acc: 0.7966
Test Loss: 0.7647 Acc: 0.7411

Epoch 43/100
Train Loss: 0.5749 Acc: 0.7994
Test Loss: 0.7219 Acc: 0.7554

Epoch 44/100
Train Loss: 0.5726 Acc: 0.8000
Test Loss: 0.7908 Acc: 0.7375

Epoch 45/100
Train Loss: 0.5846 Acc: 0.7979
Test Loss: 0.6726 Acc: 0.7734

Epoch 46/100
Train Loss: 0.5522 Acc: 0.8089
Test Loss: 0.6454 Acc: 0.7805

Epoch 47/100
Train Loss: 0.5525 Acc: 0.8080
Test Loss: 0.6552 Acc: 0.7831

Epoch 48/100
Train Loss: 0.5405 Acc: 0.8127
Test Loss: 0.6415 Acc: 0.7758

Epoch 49/100
Train Loss: 0.5319 Acc: 0.8159
Test Loss: 0.6489 Acc: 0.7801

Epoch 50/100
Train Loss: 0.5277 Acc: 0.8189
Test Loss: 0.6749 Acc: 0.7686

Epoch 51/100
Train Loss: 0.4067 Acc: 0.8602
Test Loss: 0.4672 Acc: 0.8386

Epoch 52/100
Train Loss: 0.3584 Acc: 0.8776
Test Loss: 0.4578 Acc: 0.8428

Epoch 53/100
Train Loss: 0.3390 Acc: 0.8821
Test Loss: 0.4582 Acc: 0.8434

Epoch 54/100
Train Loss: 0.3247 Acc: 0.8879
Test Loss: 0.4516 Acc: 0.8490

Epoch 55/100
Train Loss: 0.3141 Acc: 0.8901
Test Loss: 0.4525 Acc: 0.8464

Epoch 56/100
Train Loss: 0.3067 Acc: 0.8943
Test Loss: 0.4500 Acc: 0.8506

Epoch 57/100
Train Loss: 0.2955 Acc: 0.8976
Test Loss: 0.4478 Acc: 0.8513

Epoch 58/100
Train Loss: 0.2868 Acc: 0.9001
Test Loss: 0.4532 Acc: 0.8519

Epoch 59/100
Train Loss: 0.2785 Acc: 0.9037
Test Loss: 0.4555 Acc: 0.8510

Epoch 60/100
Train Loss: 0.2746 Acc: 0.9040
Test Loss: 0.4485 Acc: 0.8536

Epoch 61/100
Train Loss: 0.2661 Acc: 0.9071
Test Loss: 0.4485 Acc: 0.8546

Epoch 62/100
Train Loss: 0.2560 Acc: 0.9109
Test Loss: 0.4552 Acc: 0.8519

Epoch 63/100
Train Loss: 0.2549 Acc: 0.9113
Test Loss: 0.4523 Acc: 0.8529

Epoch 64/100
Train Loss: 0.2492 Acc: 0.9129
Test Loss: 0.4578 Acc: 0.8518

Epoch 65/100
Train Loss: 0.2416 Acc: 0.9160
Test Loss: 0.4623 Acc: 0.8528

Epoch 66/100
Train Loss: 0.2379 Acc: 0.9174
Test Loss: 0.4660 Acc: 0.8510

Epoch 67/100
Train Loss: 0.2336 Acc: 0.9188
Test Loss: 0.4669 Acc: 0.8501

Epoch 68/100
Train Loss: 0.2236 Acc: 0.9219
Test Loss: 0.4677 Acc: 0.8529

Epoch 69/100
Train Loss: 0.2255 Acc: 0.9203
Test Loss: 0.4683 Acc: 0.8528

Epoch 70/100
Train Loss: 0.2197 Acc: 0.9234
Test Loss: 0.4627 Acc: 0.8552

Epoch 71/100
Train Loss: 0.2097 Acc: 0.9288
Test Loss: 0.4711 Acc: 0.8535

Epoch 72/100
Train Loss: 0.2105 Acc: 0.9253
Test Loss: 0.4737 Acc: 0.8570

Epoch 73/100
Train Loss: 0.2056 Acc: 0.9280
Test Loss: 0.4828 Acc: 0.8518

Epoch 74/100
Train Loss: 0.1972 Acc: 0.9310
Test Loss: 0.4858 Acc: 0.8516

Epoch 75/100
Train Loss: 0.1981 Acc: 0.9313
Test Loss: 0.4906 Acc: 0.8516

Epoch 76/100
Train Loss: 0.1759 Acc: 0.9385
Test Loss: 0.4606 Acc: 0.8581

Epoch 77/100
Train Loss: 0.1615 Acc: 0.9450
Test Loss: 0.4589 Acc: 0.8596

Epoch 78/100
Train Loss: 0.1580 Acc: 0.9454
Test Loss: 0.4635 Acc: 0.8597

Epoch 79/100
Train Loss: 0.1554 Acc: 0.9469
Test Loss: 0.4637 Acc: 0.8584

Epoch 80/100
Train Loss: 0.1518 Acc: 0.9485
Test Loss: 0.4668 Acc: 0.8593

Epoch 81/100
Train Loss: 0.1505 Acc: 0.9477
Test Loss: 0.4683 Acc: 0.8597

Epoch 82/100
Train Loss: 0.1496 Acc: 0.9485
Test Loss: 0.4677 Acc: 0.8585

Epoch 83/100
Train Loss: 0.1456 Acc: 0.9505
Test Loss: 0.4713 Acc: 0.8594

Epoch 84/100
Train Loss: 0.1416 Acc: 0.9512
Test Loss: 0.4737 Acc: 0.8590

Epoch 85/100
Train Loss: 0.1409 Acc: 0.9521
Test Loss: 0.4753 Acc: 0.8592

Epoch 86/100
Train Loss: 0.1400 Acc: 0.9523
Test Loss: 0.4775 Acc: 0.8588

Epoch 87/100
Train Loss: 0.1384 Acc: 0.9528
Test Loss: 0.4788 Acc: 0.8577

Epoch 88/100
Train Loss: 0.1387 Acc: 0.9518
Test Loss: 0.4818 Acc: 0.8585

Epoch 89/100
Train Loss: 0.1362 Acc: 0.9537
Test Loss: 0.4823 Acc: 0.8584

Epoch 90/100
Train Loss: 0.1347 Acc: 0.9538
Test Loss: 0.4860 Acc: 0.8583

Epoch 91/100
Train Loss: 0.1370 Acc: 0.9520
Test Loss: 0.4864 Acc: 0.8566

Epoch 92/100
Train Loss: 0.1309 Acc: 0.9554
Test Loss: 0.4863 Acc: 0.8585

Epoch 93/100
Train Loss: 0.1314 Acc: 0.9542
Test Loss: 0.4890 Acc: 0.8599

Epoch 94/100
Train Loss: 0.1277 Acc: 0.9549
Test Loss: 0.4903 Acc: 0.8584

Epoch 95/100
Train Loss: 0.1281 Acc: 0.9560
Test Loss: 0.4920 Acc: 0.8582

Epoch 96/100
Train Loss: 0.1260 Acc: 0.9571
Test Loss: 0.4925 Acc: 0.8601

Epoch 97/100
Train Loss: 0.1277 Acc: 0.9561
Test Loss: 0.4961 Acc: 0.8604

Epoch 98/100
Train Loss: 0.1230 Acc: 0.9579
Test Loss: 0.4981 Acc: 0.8594

Epoch 99/100
Train Loss: 0.1246 Acc: 0.9567
Test Loss: 0.4963 Acc: 0.8599

Epoch 100/100
Train Loss: 0.1207 Acc: 0.9595
Test Loss: 0.5012 Acc: 0.8585

Training complete in 151m 28s
Best val Acc: 0.860400
+-------+---------------------+---------------------+---------------------+---------------------+
| Epoch |      Train Loss     |      Train Acc      |      Test Loss      |       Test ACC      |
+-------+---------------------+---------------------+---------------------+---------------------+
|   1   |  5.597684161987305  | 0.10116000000000001 |  2.317787844467163  |        0.1014       |
|   2   |  2.8181637605285643 | 0.10202000000000001 |  152.66504794921875 |        0.0978       |
|   3   |  2.662164457015991  | 0.10066000000000001 |  2.305317992019653  |        0.1005       |
|   4   |  2.5159507095336915 | 0.10626000000000001 |  2.3013097385406494 |        0.1044       |
|   5   |  2.4249416885375976 | 0.12196000000000001 |  2.254640369796753  |        0.1559       |
|   6   |  2.260620550079346  | 0.18286000000000002 |  2.0485431018829345 |        0.203        |
|   7   |  2.027170215835571  |        0.2252       |  1.8941516201019286 |        0.2569       |
|   8   |  1.9511025234603883 |       0.26328       |  1.8713503583908082 |        0.3044       |
|   9   |  1.8986714767456054 |       0.28732       |  1.7847694398880005 | 0.32270000000000004 |
|   10  |  1.7864644319915772 |       0.33028       |  1.6457983940124512 | 0.39440000000000003 |
|   11  |  1.6654642245864868 | 0.38022000000000006 |  1.5322462739944458 | 0.43160000000000004 |
|   12  |  1.5705113913345337 | 0.41988000000000003 |  1.4785417581558227 | 0.45680000000000004 |
|   13  |  1.5048716220092773 | 0.44782000000000005 |  1.3958714248657227 |        0.4883       |
|   14  |  1.4318292822265626 | 0.47722000000000003 |  1.410558832359314  |        0.4828       |
|   15  |  1.377349460144043  |       0.49752       |  1.3010577104568481 |        0.5191       |
|   16  |  1.3245690395355225 |       0.51854       |  1.2385110488891602 |        0.5521       |
|   17  |  1.2612468979263305 |       0.54278       |  1.2846428926467897 |        0.531        |
|   18  |  1.2051912934494018 |  0.5651400000000001 |  1.1898887937545777 |  0.5709000000000001 |
|   19  |  1.1522881131744385 |       0.58506       |  1.1204904958724975 |  0.6021000000000001 |
|   20  |  1.0862502717590332 |  0.6107800000000001 |  1.0363590663909912 |        0.633        |
|   21  |  1.0391264860534668 |       0.62756       |  1.0650075477600098 |        0.6261       |
|   22  |  0.986234778175354  |       0.64698       |  1.0549960264205933 |        0.6341       |
|   23  |  0.9397835676383972 |       0.66444       |  0.9948327981948852 |        0.6578       |
|   24  |  0.9080958172607422 |  0.6779000000000001 |  0.9677623798370362 |        0.6654       |
|   25  |  0.8741286783981324 |       0.69364       |  0.8751908576965332 |        0.6984       |
|   26  |  0.8381106109428406 |  0.7040200000000001 |  0.888992103767395  |        0.6926       |
|   27  |  0.8067211399650573 |       0.71616       |  0.8342957168579102 |        0.7077       |
|   28  |  0.7812549518585206 |  0.7244400000000001 |  0.7889386582374572 |        0.7245       |
|   29  |  0.7610446184158325 |  0.7322200000000001 |  0.8084777369499206 |        0.7233       |
|   30  |  0.7394685964012147 |  0.7406600000000001 |  0.7966792991638184 |        0.7245       |
|   31  |  0.7219527172279357 |       0.74758       |  0.7877902629852295 |        0.727        |
|   32  |  0.7040631879615784 |  0.7558600000000001 |  0.7902946495056152 |  0.7252000000000001 |
|   33  |  0.6867517261123657 |        0.7606       |  0.756449480342865  |        0.7349       |
|   34  |  0.6834258349609375 |       0.76236       |  0.721223167514801  |  0.7492000000000001 |
|   35  |  0.6587190056419373 |  0.7694200000000001 |  0.7026802886009216 |  0.7575000000000001 |
|   36  |  0.655641148147583  |  0.7692800000000001 |  0.7789668655395507 |        0.729        |
|   37  |  0.6327162120628357 |       0.78022       |  0.7237760466575622 |        0.7536       |
|   38  |  0.6188611623573304 |       0.78488       |  0.7174090956687927 |        0.7551       |
|   39  |  0.6177473749923706 |  0.7854800000000001 |  0.6874035218238831 |  0.7613000000000001 |
|   40  |  0.6028859351158142 |       0.79224       |  0.6435199989318847 |  0.7847000000000001 |
|   41  |  0.6143230878257752 |  0.7862800000000001 |   0.76362484664917  |        0.742        |
|   42  |  0.5886445927810668 |  0.7965800000000001 |  0.7646867671012878 |        0.7411       |
|   43  |  0.5748900702476502 |  0.7994000000000001 |  0.7218901845932006 |  0.7554000000000001 |
|   44  |  0.5725930260467529 |       0.79998       |  0.7908151494979858 |        0.7375       |
|   45  |  0.5846446306037902 |  0.7979400000000001 |  0.6726047034263611 |  0.7734000000000001 |
|   46  |  0.5521988545227051 |  0.8089200000000001 |  0.6454170646667481 |  0.7805000000000001 |
|   47  |  0.5524877719497681 |  0.8080200000000001 |  0.6552316623687744 |        0.7831       |
|   48  |  0.5404841952705384 |       0.81266       |  0.6415251020431518 |        0.7758       |
|   49  |  0.531876709728241  |  0.8159200000000001 |  0.6488860466957093 |        0.7801       |
|   50  |  0.5276873174285889 |       0.81886       |  0.6748598507881165 |  0.7686000000000001 |
|   51  |  0.4067248105430603 |       0.86016       |  0.4671768550872803 |        0.8386       |
|   52  |  0.3584159374332428 |       0.87758       |  0.4578450366973877 |        0.8428       |
|   53  |  0.3390225105953217 |  0.8821200000000001 | 0.45821271018981935 |        0.8434       |
|   54  | 0.32473760127067564 |  0.8878600000000001 | 0.45160541610717775 |  0.8490000000000001 |
|   55  |  0.3140627268600464 |       0.89012       | 0.45248478422164917 |        0.8464       |
|   56  | 0.30668855429649355 |       0.89426       | 0.45001916160583494 |        0.8506       |
|   57  |  0.2955307003593445 |  0.8976400000000001 |  0.4478180892944336 |  0.8513000000000001 |
|   58  |  0.2867567980480194 |  0.9000800000000001 | 0.45318167362213135 |        0.8519       |
|   59  |  0.2784511197757721 |  0.9037400000000001 | 0.45551826477050783 |  0.8510000000000001 |
|   60  |  0.2745651296710968 |       0.90402       | 0.44849833240509035 |        0.8536       |
|   61  | 0.26607868516921995 |  0.9070800000000001 |  0.4485297366142273 |        0.8546       |
|   62  |  0.256046674413681  |  0.9108600000000001 | 0.45524531955718994 |        0.8519       |
|   63  |  0.254869100522995  |  0.9113000000000001 |  0.4523352463245392 |        0.8529       |
|   64  |  0.2492199483013153 |  0.9129400000000001 |  0.4578011001586914 |        0.8518       |
|   65  | 0.24163890342712402 |  0.9159800000000001 |  0.4623145835876465 |        0.8528       |
|   66  | 0.23786270833969117 |       0.91744       |  0.4660232726097107 |  0.8510000000000001 |
|   67  | 0.23364970624923706 |  0.9188200000000001 |  0.4668700957298279 |  0.8501000000000001 |
|   68  |  0.2235808536720276 |  0.9219400000000001 | 0.46771119937896727 |        0.8529       |
|   69  |  0.2255024641084671 |  0.9202600000000001 |  0.4682665145874023 |        0.8528       |
|   70  | 0.21973629215717316 |  0.9234000000000001 | 0.46266299619674683 |  0.8552000000000001 |
|   71  | 0.20966480907917023 |       0.92878       |  0.4711489072799683 |        0.8535       |
|   72  |  0.2104825694513321 |  0.9252600000000001 |  0.4737342572212219 |  0.8570000000000001 |
|   73  |  0.2056388490152359 |  0.9279600000000001 |  0.482794988155365  |        0.8518       |
|   74  | 0.19716326679706572 |       0.93098       | 0.48582248706817627 |        0.8516       |
|   75  | 0.19812763473510742 |  0.9313000000000001 | 0.49055334453582766 |        0.8516       |
|   76  | 0.17592251286506652 |  0.9385000000000001 |  0.460602366065979  |  0.8581000000000001 |
|   77  |  0.1614730488371849 |       0.94496       | 0.45886383838653566 |        0.8596       |
|   78  |  0.1579563343811035 |  0.9453800000000001 | 0.46345190382003787 |        0.8597       |
|   79  | 0.15538761641979218 |  0.9469200000000001 |  0.4637104054450989 |        0.8584       |
|   80  | 0.15175129550933839 |  0.9485000000000001 |  0.4668051582336426 |  0.8593000000000001 |
|   81  | 0.15050953618049623 |  0.9476600000000001 | 0.46833118000030516 |        0.8597       |
|   82  | 0.14958858765125274 |       0.94852       | 0.46773323974609377 |        0.8585       |
|   83  |   0.14560875872612  |  0.9504600000000001 |  0.4713433973312378 |        0.8594       |
|   84  | 0.14155510222911835 |        0.9512       | 0.47365808410644533 |        0.859        |
|   85  | 0.14085680287361144 |  0.9521200000000001 | 0.47533946771621705 |  0.8592000000000001 |
|   86  |  0.1399873824119568 |  0.9522600000000001 |  0.4774640758514404 |        0.8588       |
|   87  | 0.13842420342683792 |       0.95276       | 0.47882955780029296 |        0.8577       |
|   88  |  0.1386843985271454 |  0.9517800000000001 |  0.4818275521278381 |        0.8585       |
|   89  | 0.13619597413539886 |  0.9536800000000001 |  0.4823246690750122 |        0.8584       |
|   90  | 0.13473238546848298 |       0.95376       |  0.4859841414451599 |  0.8583000000000001 |
|   91  |  0.1370047284412384 |  0.9520200000000001 |  0.4863620532989502 |        0.8566       |
|   92  | 0.13093549369335175 |  0.9554400000000001 | 0.48634164428710935 |        0.8585       |
|   93  |  0.1313776752948761 |  0.9542200000000001 | 0.48895058383941653 |        0.8599       |
|   94  |  0.1276790889263153 |  0.9548800000000001 |  0.4903421709060669 |        0.8584       |
|   95  |  0.1280599539399147 |  0.9560200000000001 |  0.4919950520515442 |  0.8582000000000001 |
|   96  | 0.12598473409175873 |  0.9570600000000001 |  0.4925013248443604 |  0.8601000000000001 |
|   97  |  0.1276523388004303 |  0.9561000000000001 |  0.4960763104438782 |        0.8604       |
|   98  | 0.12301246095180511 |       0.95786       |  0.498073508644104  |        0.8594       |
|   99  | 0.12457111587762833 |       0.95674       |  0.4963431999206543 |        0.8599       |
|  100  | 0.12073701263904571 |  0.9594800000000001 |  0.5011618096351623 |        0.8585       |
+-------+---------------------+---------------------+---------------------+---------------------+
Time elapsed: 9090.70 seconds
