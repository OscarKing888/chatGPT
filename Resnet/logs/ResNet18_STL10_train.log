Python version:  3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]
Command line arguments:
mode: train
dataset: STL10
model: ResNet18
epochs: 100
lr: 0.1
momentum: 0.9
weight_decay: 0.0005
image: ./test
showplot: False


Files already downloaded and verified
Files already downloaded and verified
====Device: cuda:0
Mode: Training, Dataset: STL10, Model: ResNet18, Model file: ResNet18_STL10_best.pth
Epoch 1/100
Train Loss: 4.0977 Acc: 0.1316
Test Loss: 28366.8495 Acc: 0.1000

Epoch 2/100
Train Loss: 3.2474 Acc: 0.1622
Test Loss: 3126.1444 Acc: 0.1000

Epoch 3/100
Train Loss: 2.2734 Acc: 0.2052
Test Loss: 151.5859 Acc: 0.1025

Epoch 4/100
Train Loss: 1.9902 Acc: 0.2454
Test Loss: 9.8829 Acc: 0.1310

Epoch 5/100
Train Loss: 1.8273 Acc: 0.2882
Test Loss: 2.1465 Acc: 0.2500

Epoch 6/100
Train Loss: 1.7249 Acc: 0.3124
Test Loss: 1.7175 Acc: 0.3249

Epoch 7/100
Train Loss: 1.6441 Acc: 0.3388
Test Loss: 1.6838 Acc: 0.3274

Epoch 8/100
Train Loss: 1.6032 Acc: 0.3564
Test Loss: 1.6547 Acc: 0.3422

Epoch 9/100
Train Loss: 1.5474 Acc: 0.3840
Test Loss: 1.6006 Acc: 0.3601

Epoch 10/100
Train Loss: 1.5141 Acc: 0.3968
Test Loss: 1.6970 Acc: 0.3606

Epoch 11/100
Train Loss: 1.4991 Acc: 0.4082
Test Loss: 1.5394 Acc: 0.3919

Epoch 12/100
Train Loss: 1.4632 Acc: 0.4244
Test Loss: 1.7791 Acc: 0.3254

Epoch 13/100
Train Loss: 1.4303 Acc: 0.4414
Test Loss: 1.5118 Acc: 0.4201

Epoch 14/100
Train Loss: 1.4102 Acc: 0.4540
Test Loss: 1.5214 Acc: 0.4085

Epoch 15/100
Train Loss: 1.3835 Acc: 0.4704
Test Loss: 1.4268 Acc: 0.4520

Epoch 16/100
Train Loss: 1.3350 Acc: 0.4968
Test Loss: 1.4412 Acc: 0.4428

Epoch 17/100
Train Loss: 1.2925 Acc: 0.5114
Test Loss: 1.4848 Acc: 0.4288

Epoch 18/100
Train Loss: 1.2702 Acc: 0.5126
Test Loss: 1.3403 Acc: 0.4964

Epoch 19/100
Train Loss: 1.2269 Acc: 0.5410
Test Loss: 1.3485 Acc: 0.5010

Epoch 20/100
Train Loss: 1.1592 Acc: 0.5716
Test Loss: 1.2914 Acc: 0.5226

Epoch 21/100
Train Loss: 1.1341 Acc: 0.5740
Test Loss: 1.2443 Acc: 0.5369

Epoch 22/100
Train Loss: 1.1082 Acc: 0.5818
Test Loss: 1.3624 Acc: 0.5075

Epoch 23/100
Train Loss: 1.1104 Acc: 0.5856
Test Loss: 1.2966 Acc: 0.5276

Epoch 24/100
Train Loss: 1.0449 Acc: 0.6112
Test Loss: 1.3747 Acc: 0.5089

Epoch 25/100
Train Loss: 1.0105 Acc: 0.6240
Test Loss: 1.4200 Acc: 0.4998

Epoch 26/100
Train Loss: 0.9627 Acc: 0.6412
Test Loss: 1.2513 Acc: 0.5539

Epoch 27/100
Train Loss: 0.9305 Acc: 0.6554
Test Loss: 1.2041 Acc: 0.5655

Epoch 28/100
Train Loss: 0.8820 Acc: 0.6748
Test Loss: 1.1843 Acc: 0.5771

Epoch 29/100
Train Loss: 0.8635 Acc: 0.6806
Test Loss: 1.1681 Acc: 0.5750

Epoch 30/100
Train Loss: 0.8758 Acc: 0.6774
Test Loss: 1.4306 Acc: 0.5119

Epoch 31/100
Train Loss: 0.8076 Acc: 0.7026
Test Loss: 1.3099 Acc: 0.5467

Epoch 32/100
Train Loss: 0.8185 Acc: 0.7000
Test Loss: 1.2793 Acc: 0.5653

Epoch 33/100
Train Loss: 0.7563 Acc: 0.7222
Test Loss: 1.3091 Acc: 0.5661

Epoch 34/100
Train Loss: 0.7548 Acc: 0.7232
Test Loss: 1.2832 Acc: 0.5736

Epoch 35/100
Train Loss: 0.7036 Acc: 0.7430
Test Loss: 1.2716 Acc: 0.5817

Epoch 36/100
Train Loss: 0.6817 Acc: 0.7508
Test Loss: 1.2637 Acc: 0.5766

Epoch 37/100
Train Loss: 0.6517 Acc: 0.7596
Test Loss: 1.1216 Acc: 0.6246

Epoch 38/100
Train Loss: 0.5864 Acc: 0.7824
Test Loss: 1.1172 Acc: 0.6254

Epoch 39/100
Train Loss: 0.5586 Acc: 0.7970
Test Loss: 1.1417 Acc: 0.6204

Epoch 40/100
Train Loss: 0.5049 Acc: 0.8194
Test Loss: 1.1636 Acc: 0.6370

Epoch 41/100
Train Loss: 0.4857 Acc: 0.8314
Test Loss: 1.2641 Acc: 0.6211

Epoch 42/100
Train Loss: 0.4974 Acc: 0.8178
Test Loss: 1.3257 Acc: 0.6075

Epoch 43/100
Train Loss: 0.4773 Acc: 0.8228
Test Loss: 1.3929 Acc: 0.6086

Epoch 44/100
Train Loss: 0.4826 Acc: 0.8212
Test Loss: 1.4749 Acc: 0.5844

Epoch 45/100
Train Loss: 0.5028 Acc: 0.8158
Test Loss: 1.1887 Acc: 0.6300

Epoch 46/100
Train Loss: 0.4175 Acc: 0.8484
Test Loss: 1.2551 Acc: 0.6016

Epoch 47/100
Train Loss: 0.3851 Acc: 0.8620
Test Loss: 1.3068 Acc: 0.6261

Epoch 48/100
Train Loss: 0.3610 Acc: 0.8684
Test Loss: 1.3793 Acc: 0.6149

Epoch 49/100
Train Loss: 0.3313 Acc: 0.8804
Test Loss: 1.2712 Acc: 0.6509

Epoch 50/100
Train Loss: 0.3227 Acc: 0.8800
Test Loss: 1.4494 Acc: 0.6206

Epoch 51/100
Train Loss: 0.2380 Acc: 0.9188
Test Loss: 1.0154 Acc: 0.6947

Epoch 52/100
Train Loss: 0.1631 Acc: 0.9506
Test Loss: 0.9714 Acc: 0.7055

Epoch 53/100
Train Loss: 0.1285 Acc: 0.9664
Test Loss: 0.9824 Acc: 0.7061

Epoch 54/100
Train Loss: 0.1104 Acc: 0.9774
Test Loss: 0.9921 Acc: 0.7084

Epoch 55/100
Train Loss: 0.1013 Acc: 0.9768
Test Loss: 1.0010 Acc: 0.7037

Epoch 56/100
Train Loss: 0.0917 Acc: 0.9826
Test Loss: 1.0139 Acc: 0.7081

Epoch 57/100
Train Loss: 0.0861 Acc: 0.9854
Test Loss: 1.0148 Acc: 0.7101

Epoch 58/100
Train Loss: 0.0797 Acc: 0.9852
Test Loss: 1.0229 Acc: 0.7083

Epoch 59/100
Train Loss: 0.0739 Acc: 0.9902
Test Loss: 1.0304 Acc: 0.7093

Epoch 60/100
Train Loss: 0.0699 Acc: 0.9874
Test Loss: 1.0420 Acc: 0.7116

Epoch 61/100
Train Loss: 0.0664 Acc: 0.9890
Test Loss: 1.0481 Acc: 0.7121

Epoch 62/100
Train Loss: 0.0632 Acc: 0.9892
Test Loss: 1.0566 Acc: 0.7089

Epoch 63/100
Train Loss: 0.0585 Acc: 0.9924
Test Loss: 1.0570 Acc: 0.7125

Epoch 64/100
Train Loss: 0.0541 Acc: 0.9934
Test Loss: 1.0673 Acc: 0.7133

Epoch 65/100
Train Loss: 0.0529 Acc: 0.9940
Test Loss: 1.0783 Acc: 0.7101

Epoch 66/100
Train Loss: 0.0505 Acc: 0.9934
Test Loss: 1.0796 Acc: 0.7094

Epoch 67/100
Train Loss: 0.0500 Acc: 0.9928
Test Loss: 1.0942 Acc: 0.7094

Epoch 68/100
Train Loss: 0.0492 Acc: 0.9932
Test Loss: 1.1009 Acc: 0.7101

Epoch 69/100
Train Loss: 0.0422 Acc: 0.9968
Test Loss: 1.0988 Acc: 0.7133

Epoch 70/100
Train Loss: 0.0412 Acc: 0.9962
Test Loss: 1.1084 Acc: 0.7131

Epoch 71/100
Train Loss: 0.0395 Acc: 0.9976
Test Loss: 1.1113 Acc: 0.7124

Epoch 72/100
Train Loss: 0.0365 Acc: 0.9960
Test Loss: 1.1173 Acc: 0.7133

Epoch 73/100
Train Loss: 0.0370 Acc: 0.9956
Test Loss: 1.1265 Acc: 0.7111

Epoch 74/100
Train Loss: 0.0348 Acc: 0.9984
Test Loss: 1.1313 Acc: 0.7131

Epoch 75/100
Train Loss: 0.0361 Acc: 0.9968
Test Loss: 1.1432 Acc: 0.7117

Epoch 76/100
Train Loss: 0.0331 Acc: 0.9974
Test Loss: 1.1381 Acc: 0.7130

Epoch 77/100
Train Loss: 0.0302 Acc: 0.9976
Test Loss: 1.1356 Acc: 0.7123

Epoch 78/100
Train Loss: 0.0324 Acc: 0.9968
Test Loss: 1.1350 Acc: 0.7129

Epoch 79/100
Train Loss: 0.0319 Acc: 0.9966
Test Loss: 1.1345 Acc: 0.7133

Epoch 80/100
Train Loss: 0.0308 Acc: 0.9978
Test Loss: 1.1348 Acc: 0.7127

Epoch 81/100
Train Loss: 0.0333 Acc: 0.9974
Test Loss: 1.1337 Acc: 0.7125

Epoch 82/100
Train Loss: 0.0296 Acc: 0.9988
Test Loss: 1.1359 Acc: 0.7130

Epoch 83/100
Train Loss: 0.0298 Acc: 0.9982
Test Loss: 1.1347 Acc: 0.7133

Epoch 84/100
Train Loss: 0.0301 Acc: 0.9986
Test Loss: 1.1364 Acc: 0.7130

Epoch 85/100
Train Loss: 0.0300 Acc: 0.9982
Test Loss: 1.1384 Acc: 0.7127

Epoch 86/100
Train Loss: 0.0303 Acc: 0.9982
Test Loss: 1.1363 Acc: 0.7131

Epoch 87/100
Train Loss: 0.0301 Acc: 0.9982
Test Loss: 1.1361 Acc: 0.7131

Epoch 88/100
Train Loss: 0.0307 Acc: 0.9982
Test Loss: 1.1348 Acc: 0.7135

Epoch 89/100
Train Loss: 0.0277 Acc: 0.9990
Test Loss: 1.1371 Acc: 0.7129

Epoch 90/100
Train Loss: 0.0286 Acc: 0.9976
Test Loss: 1.1388 Acc: 0.7115

Epoch 91/100
Train Loss: 0.0289 Acc: 0.9992
Test Loss: 1.1412 Acc: 0.7123

Epoch 92/100
Train Loss: 0.0319 Acc: 0.9972
Test Loss: 1.1423 Acc: 0.7125

Epoch 93/100
Train Loss: 0.0293 Acc: 0.9986
Test Loss: 1.1424 Acc: 0.7119

Epoch 94/100
Train Loss: 0.0289 Acc: 0.9980
Test Loss: 1.1418 Acc: 0.7110

Epoch 95/100
Train Loss: 0.0292 Acc: 0.9980
Test Loss: 1.1419 Acc: 0.7114

Epoch 96/100
Train Loss: 0.0285 Acc: 0.9986
Test Loss: 1.1427 Acc: 0.7109

Epoch 97/100
Train Loss: 0.0274 Acc: 0.9992
Test Loss: 1.1414 Acc: 0.7117

Epoch 98/100
Train Loss: 0.0275 Acc: 0.9986
Test Loss: 1.1414 Acc: 0.7123

Epoch 99/100
Train Loss: 0.0277 Acc: 0.9986
Test Loss: 1.1427 Acc: 0.7126

Epoch 100/100
Train Loss: 0.0278 Acc: 0.9988
Test Loss: 1.1439 Acc: 0.7124

Training complete in 151m 17s
Best val Acc: 0.713500
+-------+----------------------+---------------------+--------------------+---------------------+
| Epoch |      Train Loss      |      Train Acc      |     Test Loss      |       Test ACC      |
+-------+----------------------+---------------------+--------------------+---------------------+
|   1   |  4.097732832336426   |        0.1316       |   28366.84946875   |         0.1         |
|   2   |  3.247355122756958   |        0.1622       |  3126.14437109375  |         0.1         |
|   3   |  2.273359848022461   | 0.20520000000000002 | 151.58592456054689 | 0.10250000000000001 |
|   4   |  1.9901640060424806  |        0.2454       | 9.882900779724121  |        0.131        |
|   5   |  1.8272532865524291  |        0.2882       | 2.146466863632202  |         0.25        |
|   6   |  1.7248957654953003  |        0.3124       | 1.7174684009552001 |       0.324875      |
|   7   |  1.6441254600524902  |        0.3388       | 1.6837947607040404 |       0.327375      |
|   8   |  1.6031853269577026  |        0.3564       | 1.6547098550796508 |       0.34225       |
|   9   |  1.547389026260376   |        0.384        | 1.6005939712524415 | 0.36012500000000003 |
|   10  |  1.514090085220337   | 0.39680000000000004 | 1.6970429010391235 | 0.36062500000000003 |
|   11  |  1.4991144037246704  |        0.4082       | 1.539410153388977  | 0.39187500000000003 |
|   12  |  1.4632390735626222  |        0.4244       | 1.7791446237564086 |       0.325375      |
|   13  |  1.4303010055541991  |        0.4414       | 1.511849829673767  |       0.420125      |
|   14  |  1.4101901260375977  |        0.454        | 1.521382773399353  | 0.40850000000000003 |
|   15  |  1.3834719882965087  | 0.47040000000000004 | 1.4268419704437256 |        0.452        |
|   16  |  1.334970325088501   |        0.4968       | 1.4411820163726807 | 0.44275000000000003 |
|   17  |  1.2924543603897094  |  0.5114000000000001 | 1.4848181591033935 |       0.42875       |
|   18  |  1.270164109802246   |  0.5126000000000001 | 1.3403135824203491 |       0.496375      |
|   19  |  1.226906177520752   |        0.541        | 1.348535855293274  |        0.501        |
|   20  |  1.159211487007141   |        0.5716       | 1.2913698348999023 |       0.522625      |
|   21  |  1.1340714826583862  |  0.5740000000000001 | 1.2442677145004273 |       0.536875      |
|   22  |  1.1081865432739257  |        0.5818       | 1.3623547019958495 |  0.5075000000000001 |
|   23  |  1.110423441696167   |        0.5856       | 1.2966318378448487 |       0.527625      |
|   24  |  1.0448935554504395  |  0.6112000000000001 | 1.3747336139678956 |       0.508875      |
|   25  |  1.0105161470413209  |        0.624        | 1.420018521308899  |       0.49975       |
|   26  |  0.9627496686935425  |        0.6412       | 1.2513256254196168 |       0.553875      |
|   27  |  0.9305424739837647  |        0.6554       | 1.2040971984863282 |        0.5655       |
|   28  |  0.8820270880699158  |  0.6748000000000001 | 1.184323522567749  |       0.577125      |
|   29  |  0.8635477360725403  |        0.6806       |  1.16810462474823  |  0.5750000000000001 |
|   30  |  0.8758333846092224  |        0.6774       | 1.4305807933807373 |       0.511875      |
|   31  |  0.8076049966812133  |        0.7026       | 1.309891580581665  |       0.54675       |
|   32  |  0.818501365852356   |  0.7000000000000001 | 1.2792679920196532 |       0.56525       |
|   33  |  0.756310943222046   |  0.7222000000000001 | 1.3091357936859132 |       0.566125      |
|   34  |  0.7547643080711365  |  0.7232000000000001 | 1.283202730178833  |       0.573625      |
|   35  |  0.7036411555290222  |        0.743        | 1.2715806064605712 |       0.58175       |
|   36  |  0.6816595903396606  |        0.7508       | 1.2637219228744507 |       0.576625      |
|   37  |  0.6517154644966126  |        0.7596       | 1.1216021156311036 |       0.624625      |
|   38  |  0.5863529116630554  |        0.7824       | 1.1172130975723267 |       0.625375      |
|   39  |  0.5586212844848633  |        0.797        | 1.141672384262085  |       0.620375      |
|   40  |  0.504885595703125   |        0.8194       | 1.1636405220031738 |        0.637        |
|   41  |  0.4856518226623535  |        0.8314       | 1.2641467580795287 |       0.621125      |
|   42  | 0.49735755891799927  |  0.8178000000000001 | 1.3257377376556396 |        0.6075       |
|   43  | 0.47725928239822385  |  0.8228000000000001 | 1.3928871784210206 |       0.608625      |
|   44  | 0.48264642415046694  |        0.8212       | 1.4748520336151123 |       0.584375      |
|   45  |  0.5028079275131225  |  0.8158000000000001 | 1.1887018785476684 |         0.63        |
|   46  |  0.4175095674991608  |        0.8484       | 1.2551003303527832 |       0.601625      |
|   47  |  0.3850810727119446  |        0.862        | 1.3067784004211427 |       0.626125      |
|   48  |  0.3609504852771759  |  0.8684000000000001 | 1.3793348617553711 |  0.6148750000000001 |
|   49  |  0.3312834533691406  |  0.8804000000000001 | 1.2711793050765992 |       0.650875      |
|   50  | 0.32265790009498596  |         0.88        | 1.449422315597534  |       0.620625      |
|   51  | 0.23801616508960724  |  0.9188000000000001 | 1.0153838033676148 |       0.69475       |
|   52  | 0.16307384791374208  |        0.9506       | 0.9713603982925415 |        0.7055       |
|   53  | 0.12854727458953857  |        0.9664       | 0.9823673582077026 |       0.706125      |
|   54  | 0.11043933280706406  |        0.9774       | 0.9920751276016235 |       0.708375      |
|   55  | 0.10128373794555665  |        0.9768       | 1.0010495901107788 |       0.70375       |
|   56  | 0.09172356411218643  |        0.9826       | 1.0138527975082396 |       0.708125      |
|   57  | 0.08609852392673492  |        0.9854       | 1.0148299732208252 |       0.710125      |
|   58  | 0.07971053149700165  |  0.9852000000000001 | 1.0228796977996826 |       0.70825       |
|   59  | 0.07393115742206574  |  0.9902000000000001 | 1.0303601579666137 |       0.70925       |
|   60  | 0.06987022004127502  |        0.9874       | 1.0420435256958007 |  0.7116250000000001 |
|   61  |  0.0664362688422203  |  0.9890000000000001 | 1.0481140117645265 |       0.712125      |
|   62  | 0.06322486618161202  |  0.9892000000000001 | 1.0566383838653564 |       0.708875      |
|   63  | 0.058501419007778166 |  0.9924000000000001 | 1.057020817756653  |        0.7125       |
|   64  | 0.054125811105966565 |  0.9934000000000001 | 1.0672535991668701 |       0.71325       |
|   65  | 0.05288366820216179  |        0.994        | 1.078300958633423  |       0.710125      |
|   66  |  0.050526178586483   |  0.9934000000000001 | 1.0796376705169677 |       0.709375      |
|   67  | 0.049982420068979266 |        0.9928       | 1.094215051651001  |       0.709375      |
|   68  | 0.04920000003576279  |  0.9932000000000001 | 1.1008506164550782 |       0.710125      |
|   69  | 0.04216087291240692  |        0.9968       | 1.0988361301422118 |       0.71325       |
|   70  | 0.04116414588689804  |  0.9962000000000001 | 1.1084459819793702 |       0.713125      |
|   71  | 0.03952637513279915  |        0.9976       | 1.1112500858306884 |       0.712375      |
|   72  | 0.036486690962314605 |        0.996        | 1.1172682151794433 |       0.71325       |
|   73  | 0.03704063322544098  |        0.9956       | 1.1265173625946046 |       0.711125      |
|   74  | 0.03480321795940399  |  0.9984000000000001 |  1.13134397315979  |       0.713125      |
|   75  | 0.036110891586542126 |        0.9968       | 1.1431660022735595 |       0.71175       |
|   76  | 0.03311520813107491  |  0.9974000000000001 | 1.1381307649612427 |        0.713        |
|   77  | 0.03019976552426815  |        0.9976       | 1.1355897903442382 |       0.71225       |
|   78  | 0.032370438212156294 |        0.9968       | 1.1349565601348877 |       0.712875      |
|   79  | 0.03191829774081707  |        0.9966       | 1.1345037517547607 |       0.71325       |
|   80  | 0.030841302388906477 |        0.9978       | 1.1347785634994507 |       0.71275       |
|   81  | 0.03328997450470925  |  0.9974000000000001 | 1.1336602506637574 |        0.7125       |
|   82  | 0.029633744436502456 |        0.9988       | 1.1359389572143554 |        0.713        |
|   83  | 0.029803521394729613 |  0.9982000000000001 | 1.1346748752593994 |       0.71325       |
|   84  | 0.030149543452262877 |        0.9986       | 1.1363850317001343 |        0.713        |
|   85  | 0.029995402055978775 |  0.9982000000000001 | 1.138408166885376  |       0.71275       |
|   86  | 0.030258790421485902 |  0.9982000000000001 | 1.1362688732147217 |       0.713125      |
|   87  | 0.03007427106499672  |  0.9982000000000001 | 1.1360600643157959 |       0.713125      |
|   88  | 0.030726274538040162 |  0.9982000000000001 | 1.1348014888763427 |        0.7135       |
|   89  | 0.027699574667215347 |        0.999        | 1.1370837593078613 |       0.712875      |
|   90  | 0.02863951909840107  |        0.9976       | 1.1388186292648315 |        0.7115       |
|   91  | 0.028944705444574358 |  0.9992000000000001 |  1.14119428730011  |       0.71225       |
|   92  | 0.03190186089873314  |  0.9972000000000001 | 1.1422808485031128 |        0.7125       |
|   93  | 0.029300168305635452 |        0.9986       | 1.1423905696868897 |       0.711875      |
|   94  | 0.028896083617210386 |        0.998        | 1.141816128730774  |        0.711        |
|   95  | 0.029203251904249192 |        0.998        | 1.1418878107070922 |       0.711375      |
|   96  |  0.0284580279648304  |        0.9986       | 1.142721833229065  |       0.710875      |
|   97  | 0.027418353071808815 |  0.9992000000000001 | 1.141372847557068  |       0.71175       |
|   98  | 0.027530627381801606 |        0.9986       | 1.1414323987960815 |       0.71225       |
|   99  | 0.027731426078081132 |        0.9986       | 1.1427230529785157 |  0.7126250000000001 |
|  100  | 0.027826557612419128 |        0.9988       | 1.143916353225708  |       0.712375      |
+-------+----------------------+---------------------+--------------------+---------------------+
Time elapsed: 9088.22 seconds
